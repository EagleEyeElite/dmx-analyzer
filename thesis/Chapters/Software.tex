\chapter{Software}
\lhead{Kapitel 5: \emph{Software}}

Die Hardware alleine reicht nicht aus, um den Bildschirm mit den analysierten DMX Paketen zu füttern. Die Hardware gibt uns nur die rohen aufgenommen Daten und eine physische Verbindung zwischen Bildschirm und dem Raspberry Pi. In dem Projekt wurde ein Programm geschrieben, um beide Elemente zu verbinden. Die Bachelorarbeit beschreibt auch, die Motivation, hinter den Entscheidungen der verwendeten Softwarelösungen. Die Auswahl der verwendeten Technologien wird im Folgenden beschrieben.

\section{Verwendete Technologien}
Als Basis wird das Linux OS für den Raspberry Pi verwendet: Raspberry Pi OS.

Ein aufgenommenes DMX Paket mit einer Abtastrate von 24Mhz umfässt 1.2 Millionen Abtastpunkte:

\[\SI{50}{\ms} \cdot \SI{24}{\cdot 10^6 \frac{Abtastungen}{s}} \approx \SI{1.2}{\cdot 10^6 Abtastungen}\]

Die Verarbeitung des DMX Signales muss daher schnell erfolgen. Auch die Bildschirmsteuerung muss möglichst schnell laufen, damit der Bildschirm auch Animationen flüssig darstellen kann. Außerdem muss das Programm direkt mit dem USB Logikanalysator kommunizieren. Die verwendete Programmiersprache muss also schnell sein und direkt mit der Hardware und dem Betriebssystem kommunizieren können.

Die Programmiersprache sollte daher eine kompilierte Sprache und keine interpretierte Sprache sein. Bei einer kompilierten Sprache wird der Quellcode bereits vor dem Ausführen in Maschinensprache übersetzt. Eine interpretierte Sprache interpretiert den Quellcode erst während der Ausführung und ist daher generell langsamer.

Programme mit diesen Anforderungen wurden früher oft in C, C++ oder vergleichbaren Programmiersprachen geschrieben. Seit einigen Jahren gewinnt eine neue Programmiersprache deutlich an Popularität: Rust. Für dieses Projekt, ist der Großteil der Logik in Rust geschrieben.
Für die Kommunikation mit dem USB Logikanalysator, die Analysierung des DMX Paketes und die Ansteuerung der LED Matrix werden an bereits existierenden Lösungen angeknüpft. Diese Interaktion kann mithilfe von externen Bibliotheken umgesetzt werden.

\section{Bildschirm Treiber}

Für die Steuerung des Bildschirmes auf dem Pi wird die C Bibliothek \emph{rpi rgb led matrix} \cite{githubRpi-rgb-led-matrix} benutzt. Es gab bereits eine von der Gemeinschaft bereitgestellte Rust Schnittstelle für diese C Bibliothek. Die grafischen Bausteinelemente wie z.B. Text, Linien und andere Formen werden mithilfe der Bibliothek \emph{embedded grahics}
\cite{githubEmbedded-graphics}
umgesetzt. Dadurch muss nicht jeder Pixel einzeln gesetzt werden. Es können verschiedene Bausteilelemente abstrahiert auf den Bildgenschirm gebracht werden. 

%TODO Bild einfügen?


\section{Logikanalysator}
Für die Kommunikation mit dem Logikanalysator wird die Bibliothek \emph{sigrok} \cite{githubLibsigrok} verwendet. Die Bibliothek ist in C geschrieben. Leider gab es keine geeignete Rust Schnittstelle, um mit dieser Bibliothek zu interagieren. Daher habe ich meine eigene C Bibliothek geschrieben, welche die \emph{sigrok} C Bibliothek einbindet, um mit dem USB Logikanalysator zu kommunizieren. Für meine eigene C Bibliothek habe ich dann ein Rust Interface aufgebaut, um sie aus meinem Rust Quellcode heraus aufzurufen.

Die empfangenen Daten vom USB Logikanalysator müssen jedoch noch verarbeitet werden. Dafür wird eine weitere Bibliothek verwendet: \emph{libsigrokDecode}\cite{githubLibsigrokDecode}.
Diese Bibliothek wurde nicht für Echtzeit Analysen ausgelegt. Die Bibliothek ist in Python geschrieben. Python ist eine interpretierte Sprache und daher langsamer. Bei der Anzahl der Abtastpunkte, die bei 24 Mhz aufgenommen werden, kommt der Raspberry Pi an seine Grenzen. Der Raspberry Pi braucht ungefähr 3 Sekunden um ein DMX Paket zu analysieren.

Mein geschriebenes Programm unterstützt verschiedene Abtastraten. Ist ein schnelleres und reaktives Verhalten gewünscht, und ungenauere Zeitmessungen kein Problem, kann die Samplingrate bis zu 2 MHz herunter gestellt werden.

% TODO bit banging tests?
%Auch ist der DMX Decoder nicht der beste.


\section{Entwicklung mithilfe von Simulation}
Der Raspberry Pi ist im Vergleich zu einem normalen Computer relativ langsam. Das komplette Programm neu auf dem Pi zu kompilieren braucht etwa 3-4 Minuten. Beim Updaten von kleinen Quellcodeänderungen benötigt der Pi einige Sekunden. Ein handelsüblicher Computer \footnote{getestet mit einem M1 MacBook Pro} benötigt ca. 30 Sekunden, um das komplette Programm zu kompilieren und ca. 1 Sekunde bei kleinen Quellcode-Änderungen. Der Entwicklungsprozess wird dadurch erheblich verlangsamt. Es wurden mehrere Ansätze getestet, um den Entwicklungsprozess zu vereinfachen.

Zunächst war die Überlegung das Programm auf einen normalen Computer zu kompileren und nur das fertige Programm auf den Raspberry Pi zu kopieren und dort auszuführen. Dieses Verfahren nennt sich quer kompilieren (\emph{cross compile}). Dafür ist es erforderlich eine komplette Werkzeugkette (\emph{toolchain}) aufzubauen. Diese Werkzeugkette muss für den verwendeten Raspberry Pi maßgeschneidert werden. Alle Bibliotheken müssen ebenfalls über diese Werkzeugkette kompiliert werden. Am Anfang des Projektes, gab es noch wenige Abhängigkeiten. Die Abhängigkeiten wurden jedoch schnell zu komplex, um die Werkzeugkette mit geringem Aufwand aufrechtzuerhalten.

Docker bietet eine portable und konsistente Laufzeitumgebung für Softwareanwendungen. Es wurde auch probiert Docker zu verwenden, um die Abhängigkeiten besser kontrollieren zu können. Das Kompilieren während des Bauens eines Docker Containers war jedoch ebenfalls nicht schnell genug.

Für das Projekt wurde ein anderer Ansatz gewählt: Simulation.

\begin{figure}[H]
	\centering
	\shadowimage[width=0.5\linewidth]{Pictures/simulatedLedMatrix}
	\caption{Simulierte LED Matrix \cite{githubEmbedded-graphicsSimulator}}
\end{figure}


Die Bibliothek, welche die grafischen Bausteinelemente auf der LED Matrix umsetzt, unterstützt ebenfalls die Simulation eines Bildschirmes auf einem PC \cite{githubEmbedded-graphicsSimulator}. Die simulierte LED Matrix muss etwas anders im Quellcode eingebunden werden, als die Hardware LED Matrix. Der Vorteil jedoch ist, dass die Logik für das Rendern des Bildes exakt gleich ist, und derselbe Quellcode genutzt wird.

Für die Kommunikation mit dem USB Logikanalysator wird die Bibliothek \emph{sigrok} \cite{githubLibsigrok} benutzt. \emph{Sigrok} unterstützt nicht nur die Kommunikation mit dem USB Gerät, sondern auch das Abspielen eines vorher  mit dem USB Logikanalysator aufgenommen Signals. So kann ein DMX Paket aufgenommen werden, und beim Entwickeln einfach zum Testen genutzt werden. Beim Entwickeln der Software ist es hilfreich, nicht jedes mal die gesamte Hardware aufbauen zu müssen. Der Computer, der zum Entwickeln benutzt wird, benötigt daher auch alle Abhängigkeiten und Bibliotheken, die das Programm verwendet. Dies ist bei Linux mit \begin{verbatim}sudo apt install libsigrok\end{verbatim} möglich. Auf dem Mac ist dies mithilfe \begin{verbatim}brew install libsigkrok\end{verbatim} möglich. Leider hat Windows keinen eigenen Paketmanager. Auf Windows ist dies auch möglich, erfordert aber etwas mehr Arbeit.

Durch die Unterstürzung einer Simulation, können andere Entwickler/-innen das Programm ausprobieren, ohne selber die Hardware zur Verfügung zu haben. Entwickler/-innen, die sich einen genaueren Eindruck vom Projekt machen wollen, können dies mithilfe der Simulation sehr einfach machen.


\section{Signal Decodierung}

% TODO callback to c in rust for usb analyzer

Das Signal wird in Echtzeit vom Logikanalysator erfasst. Diese Rohdaten werden dann für die Signaldecodierung mithilfe der \emph{sigrokDecode} \cite{githubLibsigrokDecode} Bibliothek decodiert. Die Aufnahme der Rohdaten als auch die Signaldecodierung wird asynchron in einem separaten Ausführungsstrang (\emph{Thread}) umgesetzt. Die Bibliothek, welche zum Decodieren verwendet wird, gruppiert jedoch nicht das gesamte DMX Paket, sondern streamt die einzelnen decodierten Ereignisse wie z.B. das Pause Signal, Mark \emph{After Break (MAB)} oder die einzelnen Bits.

Die asynchron laufenden Ausführungsstränge müssen für den Datenaustausch synchronisiert werden. Für die Kommunikation werden sogenannte Rust Kanäle verwendet.

Das DMX Pakets wird mithilfe eines Zustandsautomaten zusammengefasst:

\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\node[state, initial] (break) {Break};
		\node[state, right of=break] (mab) {MAB};
		\node[state, accepting, right of=mab] (byte) {Byte};
		\node[state, below of=byte] (startbit) {Startbit};
		\node[state, below of=startbit] (bit) {Bit};
		\node[state, below of=bit] (stopbit) {Stopbit};
		\draw
		(break) edge (mab)
		(mab) edge (byte)
		(byte) edge (startbit)
		(startbit) edge (bit)
		(bit) edge[loop right] node{8x}
		(bit) edge (stopbit)
		(startbit) edge[above] (bit)
		(stopbit) edge[loop right] node{2x}
		(stopbit) edge[bend left, left] node{2x $\le$ 513x} (byte);
	\end{tikzpicture}
	\caption{DMX Zustandsautomat}
	\label{fig:my_label}
\end{figure}

Der Zustandsautomaten empfängt die einzelnen decodierten Ereignisse, prüft die Reihenfolge und fasst ein komplett empfangenes Paket zusammen. Das Paket fängt mit der Pause und dem \emph{Mark After Break (MAB)} an. Danach folgen bis zu 513 Bytes. Der erste Byte ist der \emph{Startcode}. Danach folgt mindestens ein und bis zu 512 weitere Kanäle.

Die Zusammenfassung der DMX Pakete und das Rendern des Bildes werden ebenfalls in separierten Ausführungsstränge berechnet, da beide Berechnungen sich nicht gegenseitig blockieren sollten. Ist ein DMX Paket komplett zusammengefasst, so wird dieses auch wiederum über einen Rust Kanal asynchron zum Ausführungsstrang des Bildschirmrenderers übertragen.  

\section{Signal Darstellung}
Das analysierte Signal wird als Wellenform auf dem Bildschirm dargestellt.
Aus dem Signal werden kleinere Ausschnitte ausgewählt und auf verschiedenen Bildschirmansichten dargestellt, weil der Bildschirm eine relativ kleine Auflösung aufweist.

\subsection{Reset Sequenz}
Jedes DMX Paket fängt mit der Reset Sequenz an.

\begin{figure}[H]
	\centering
	\shadowimage[width=0.5\linewidth]{Pictures/screenshotResetSequence}\\
	\caption{Reset Sequenz}
\end{figure}
Diese Sequenz beseht aus dem Pause Signal, der \emph{Mark After Break (MAB)} und dem \emph{Startcode}. Der \emph{Startcode} ist bei DMX Paketen immer 0. Jeder Byte, der Übertragen wird, enthält einen \emph{Startcode} (in grün) und zwei Stopbits (in rot). Die Zeitabstände werden unter der Wellenform dargestellt.

Aufgrund der kleinen Auflösung sind die Zeitabstände nicht maßstabsgetreu. Ein Bit ist eigentlich nur 4µs lang. Auf dem Bildschirm sieht er jedoch deutlich länger aus. Am unterem Bildschirm Rand befindet sich die Abtastrate, mit der das Signal aufgenommen wird. Aus der Abtastrate leitet sich auch die Messunsicherheit der Zeitabstände ab.

\subsection{Kanal 1}

Die Dekodierung eines Bytes wird auf einer anderen Bildschirmansicht dargestellt.

\begin{figure}[H]
	\centering
	\shadowimage[width=0.5\linewidth]{Pictures/screnshotChannel1}\\
	\caption{Kanal 1}
\end{figure}

Die Bits, abgesehen von den Start- und Stopbits, werden auch als Wellenform abgebildet. Der Wert des Kanals ist oben im Bild als Dezimalwert angegeben: 101. In Binär ist dies 0b1100101. Beim Dmx Protokoll wird jedoch das höchstwertigen Bit zuerst versendet. Daher ist die Reihenfolge in der Wellenansicht umgedreht.

\subsection{Anwendungsbeispiel}

Das Ziel des Projektes ist es, Studierenden das DMX Paket auf einer anschaulichen Art und Weise zu zeigen. Im Idealfall bekommen die Studierenden ein intuitives Gefühl für die Anwendungsmöglichkeiten des Protokolls.

Auf einer Bühne werden die verschiedenen Aspekte der Leuchten über die DMX Kanäle kontrolliert. Ein Kanal kann dabei die Helligkeit oder auch die Farbe der Leuchten oder ähnliches steuern.

In dem Projekt möchte ich den Studierenden auch ein Gefühl mitgeben, wie die Kanäle für die Lichtsteuerung eingesetzt werden können.

Dafür habe ich eine eigene \emph{3D Render Engine} in Rust aufgebaut, ohne die Verwendung von externen Bibliotheken\footnote{Die Implementierung ist an einer bereits existierender Render Engine angelehnt. Weitere Details sind im Quellcode kommentiert.}.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\shadowimage[width=0.9\linewidth]{Pictures/screenshotRenderCyan}
		\caption{Farbe: Blau/ Cyan}
		\label{fig:renderSpaceshipCyan}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\shadowimage[width=0.9\linewidth]{Pictures/screenshotRenderYellow}
		\caption{Farbe: Gelb}
		\label{fig:renderSpaceshipYellow}
	\end{subfigure}
	\caption{Farbe gesteuert von Kanal 1-3}
	\label{fig:spaceship_renderes}
\end{figure}

Im Hintergrund befindet sich ein rotierendes Raumschiff. Im Vordergrund sind einige weiße Balken zu sehen. Die Balken bilden die ersten 64 Kanäle entlang der x-Achse ab. Der Wertebereich eines Kanals (0-255) wird auf die Höhe des Bildschirms (64 Pixel) abgebildet.

Die Farbe des Raumschiffes kann mithilfe der DMX Kanäle gesteuert werden. Im Beispiel kontrollieren die ersten 3 Kanäle die \emph{RGB} Werte des Raumschiff. Im ersten Bild\ref{fig:renderSpaceshipCyan} ist der 2. (Grün) und 3. Kanal (Blau) dominierend. Die resultierende Farbe des Raumschiffes ist daher ein Cyan blau. Im zweiten Bild \ref{fig:renderSpaceshipYellow} dominieren die Kanäle 1 und 2. Daher ist die resultierende Farbe eine Mischung aus Rot und Grün: Gelb.

Zur Demonstrierung sind im Bild \ref{fig:spaceship_renderes} noch weitere Kanäle angezeigt. Diese Kanäle verändern keine weiteren Eigenschaften des Raumschiffes, und deuten an, dass eine andere Leuchte, die dasselbe Signal erhält, von diesen anderen Kanälen kontrolliert werden könnte.

Die Studierenden sollend dadurch ein Verständnis bekommen, wie die Kanäle die Aspekte einer Leuchte steuern können.

\section{Ergebnisse}

Die simulierten Bildschirmansichten funktionieren ebenfalls auf der echten Hardware. In den Bildern \ref{fig:dmxScreensOnHardware} sind die verschiedenen Ansichten aufgezeigt:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.32\textwidth}
		\centering
		\shadowimage[angle=-90,width=.93\linewidth]{Pictures/finishedProduct/dmxAnalyzer2}
		\caption{Kanal 1}
	\end{subfigure}
	\hfill
	\begin{subfigure}{.32\textwidth}
		\centering
		\shadowimage[angle=-90,width=.93\linewidth]{Pictures/finishedProduct/dmxAnalyzer3}
		\caption{Reset Sequenz}
	\end{subfigure}
	\hfill
	\begin{subfigure}{.32\textwidth}
		\centering
		\shadowimage[angle=-90,width=.93\linewidth]{Pictures/finishedProduct/dmxAnalyzer4}
		\caption{Raumschiff}
	\end{subfigure}
	\caption{Bildschirmansichten auf der Hardware}
	\label{fig:dmxScreensOnHardware}
\end{figure}


\section{Kontrollierung der DMX Signalanalyse}

Das analysierte Signal wird mithilfe eines Oszilloskope überprüft, um die dargestellte Wellenform zu verifizieren. Das Oszilloskop ermittelt den Durchschnitt von 4 Aufnahmen, um das rauschfreie Signal abzubilden.

Die analysierten Zeitabstände zeigen einen Unterschied zwischen Logik Analysator und dem Oszilloskope.

\begin{figure}[H]
	\centering
	\resizebox{\textwidth}{!}{%
		\shadowimage[align=b, height=8cm]{Pictures/screenshotResetSequence}%
		\shadowimage[align=b, height=7.7cm]{Pictures/oscilloscopeResetSequence1}%
	}\\
	\vspace{0.5cm}
	\begin{tabular}{ r | l | l | l}
		Bezeichnung: & Logikanalysator & Oszilloskope & $\Delta Zeit$ \\ 
		\hline
		Pause & 102.91 µs & 101.4 µs & 1.51 µs\\
		MAB & 31.283 µs & 31.65 µs & 0.367 µs\\
	\end{tabular}
	\caption{Vergleich Projekt und Oszilloskope: Reset Sequenz}
\end{figure}

Die analysierten Zeitabstände zeigen einen Unterschied zwischen dem  Logikanalysator und dem Oszilloskope. Die Messunsicherheit des Logikanalysators beträgt 41ns. Die mit dem Oszilloskope gemessene Zeit hat jedoch eine Abweichung größer als die Messunsicherheit.

Im nächsten Bild wird die Wellenform des ersten Kanals verglichen:

\begin{figure}[H]
	\centering
	\resizebox{\textwidth}{!}{%
		\shadowimage[align=b, height=8cm]{Pictures/screnshotChannel1}%
		\shadowimage[align=b, height=7.7cm]{Pictures/oscilloscopeChannel1}%
	}\\
	\vspace{0.5cm}
	\begin{tabular}{ r | l | l | l}
		Bezeichnung: & Logikanalysator & Oszilloskope & $\Delta Zeit$ \\ 
		\hline
		Bit & 3.895 µs & ~4 µs (abgelesen) & 0.105 µs\\
		Byte & 31.16 µs & ~32.00 µs (abgelesen) & 0.84 µs\\
	\end{tabular}
	\caption{Vergleich Projekt und Oszilloskope: Kanal 1}
\end{figure}


Auf dem linken Bildschirm, wird aufgrund der kleinen Auflösung die Start- und Stopbits nicht dargestellt. Das erste und letzte Bit vom ersten Kanal ist beim Oszilloskope mit dem Mauszeiger markiert. Die dargestellte Bytereihenfolge ist identisch mit der Reihenfolge des Oszilloskops.

Die Zeitmessunsicherheit bei einer Abtastrate von 24 Mhz beträgt 41ns. Die Abweichungen sind oft größer. Beim Pause Signal ist die Abweichung 1.51µs. Die Anstiegszeit des DMX Signals ist leider auch nicht perfekt und könnte die Ursache der Messdifferenz sein.

\begin{figure}[H]
	\centering
	\shadowimage[width=0.8\linewidth]{Pictures/oscilloscopeRiseTime}
	\caption{Anstiegszeit des Signals}
\end{figure}

Die Anstiegszeit beträgt 1.010 µs. Es ist möglich, dass der Logikanalysator erst bei einem anderen Logikpegelschwellenwert ausschlägt als das Oszilloskope. Der untersuchte Zeitunterschied könnte dadurch erklärt werden.
